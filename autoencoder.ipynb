{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\ggplot\\utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\ggplot\\stats\\smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from train_val_split import train_validation_split\n",
    "import ggplot as gplt\n",
    "from tools.mean_encoder import *\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from autoencoders_keras.vanilla_autoencoder import VanillaAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"dataset/train_val/training_set.csv\")\n",
    "test_set = pd.read_csv(\"dataset/train_val/testing_set.csv\")\n",
    "train_set[\"order_id\"] = train_set[\"order_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\S\\travel_data\\tools\\mean_encoder.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  x_val[colname] = means\n"
     ]
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"dataset/train_val/training_set.csv\")\n",
    "test_set = pd.read_csv(\"dataset/train_val/testing_set.csv\")\n",
    "train_set[\"order_id\"] = train_set[\"order_id\"].astype(str)\n",
    "\n",
    "\n",
    "airport_me = pd.read_csv(\"./feature_extraction/airport_mean_encoding.csv\")\n",
    "airport_me[\"order_id\"] = airport_me[\"order_id\"].astype(str)\n",
    "train_set = pd.merge(train_set, airport_me, on=\"order_id\", how=\"left\")\n",
    "test_set = pd.merge(test_set, airport_me, on=\"order_id\", how=\"left\")\n",
    "\n",
    "\n",
    "drop_col = [x for x in train_set.columns if \"time_dist\" in x]\n",
    "\n",
    "y_train = train_set[\"deal_or_not\"]\n",
    "for table in [train_set, test_set]:\n",
    "    table.drop(columns=[\"deal_or_not\", \"group_id\", \"order_id\"] + drop_col, inplace=True)\n",
    "    table.fillna(table.mean(), inplace=True)\n",
    "    \n",
    "\n",
    "cv = StratifiedKFold(5, shuffle=True, random_state=851206)\n",
    "#mean_enc_col = [\"source1_unit\", \"area\", 'source1_source2', 'source1_source2_unit',\n",
    "#                'source2_unit'] # 這個column是catboost feature importance最高的feature\n",
    "mean_enc_col = [\"source1_unit\"]\n",
    "#mean_enc_col = list(train_set.columns[cat_feature])\n",
    "train_set = mean_encoder(train_set, y_train, mean_enc_col, \"deal_or_not\", cv)\n",
    "test_set = test_set_encoder(train_set, y_train, test_set, mean_enc_col, \"deal_or_not\")\n",
    "\n",
    "drop_col = ['source1_source2', 'source1_unit', 'source2_unit',\n",
    "       'source1_source2_unit', 'order_month', 'order_quarter', 'subline_area',\n",
    "       'begin_month', 'begin_quarter', 'abroad_airport', 'home_airport',\n",
    "       'abroad_hour', 'abroad_part_of_day', 'abroad_DoY', 'abroad_DoW',\n",
    "       'abroad_DoM', 'home_DoW', 'home_DoM', 'home_DoY', 'home_hour',\n",
    "       'home_part_of_day']\n",
    "for table in [train_set, test_set]:\n",
    "    table.drop(columns=drop_col, inplace=True)\n",
    "\n",
    "#and \"DoY\" not in col\n",
    "cat_feature = []\n",
    "key_words = [\"source\", \"unit\", \"sub\", \"area\", \"order\", \"begin\", \"_airport\",\n",
    "             \"abroad\", \"home\"]\n",
    "for i, col in enumerate(train_set.columns):\n",
    "    for kw in key_words:\n",
    "        if kw in col and \"duration\" not in col and \"DoY\" not in col and \"target\" not in col \\\n",
    "         and \"accum\" not in col and i not in cat_feature:\n",
    "            cat_feature.append(i)\n",
    "\n",
    "            \n",
    "#train_x.drop(columns=mean_enc_col, inplace=True)\n",
    "#val_x.drop(columns=mean_enc_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_set = pd.concat([train_set, test_set])\n",
    "whole_set.index = list(range(whole_set.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_rep(table, cat_feature):\n",
    "    dummy = pd.get_dummies(table[cat_feature[0]])\n",
    "    for col in cat_feature[1:]:\n",
    "        dummy = pd.concat([dummy, pd.get_dummies(table[col])], axis=1)\n",
    "    return pd.concat([table.drop(columns=cat_feature), dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_dummy = dummy_rep(whole_set, whole_set.columns[cat_feature])\n",
    "train_dummy = whole_dummy.iloc[0:train_set.shape[0]]\n",
    "test_dummy = whole_dummy.iloc[train_set.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_dummy_std = scaler.fit_transform(train_dummy)\n",
    "test_dummy_std = scaler.transform(test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(297020, 382)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummy_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(382, ))\n",
    "\n",
    "# encoder\n",
    "#encoded = Dense(256, activation=\"relu\")(input_layer)\n",
    "#encoded = Dropout(0.8)(encoded)\n",
    "encoded = Dense(128, activation=\"relu\")(input_layer)\n",
    "#encoded = Dropout(0.8)(encoded)\n",
    "encoded = Dense(64, activation=\"relu\")(encoded)\n",
    "encoded = Dense(32, activation=\"relu\")(encoded)\n",
    "\n",
    "#decoder\n",
    "#decoded = Dense(32, activation=\"relu\")(encoded)\n",
    "decoded = Dense(64, activation=\"relu\")(decoded)\n",
    "decoded = Dense(128, activation=\"relu\")(decoded)\n",
    "#encoded = Dropout(0.8)(decoded)\n",
    "#encoded = Dense(256, activation=\"relu\")(decoded)\n",
    "#encoded = Dropout(0.8)(decoded)\n",
    "output_layer = Dense(382, activation=\"sigmoid\")(decoded)\n",
    "\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 297020 samples, validate on 99895 samples\n",
      "Epoch 1/50\n",
      "297020/297020 [==============================] - 19s 64us/step - loss: 0.9347 - val_loss: 8.7272\n",
      "Epoch 2/50\n",
      "297020/297020 [==============================] - 18s 60us/step - loss: 0.9050 - val_loss: 8.7183\n",
      "Epoch 3/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.9010 - val_loss: 8.7170\n",
      "Epoch 4/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8977 - val_loss: 8.7120\n",
      "Epoch 5/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8907 - val_loss: 8.7055\n",
      "Epoch 6/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8859 - val_loss: 8.7039\n",
      "Epoch 7/50\n",
      "297020/297020 [==============================] - 18s 60us/step - loss: 0.8831 - val_loss: 8.7011\n",
      "Epoch 8/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8801 - val_loss: 8.6994\n",
      "Epoch 9/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8783 - val_loss: 8.6983\n",
      "Epoch 10/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8767 - val_loss: 8.7047\n",
      "Epoch 11/50\n",
      "297020/297020 [==============================] - 18s 59us/step - loss: 0.8750 - val_loss: 8.7025\n",
      "Epoch 12/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8728 - val_loss: 8.7017\n",
      "Epoch 13/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8695 - val_loss: 8.6982\n",
      "Epoch 14/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8665 - val_loss: 8.6990\n",
      "Epoch 15/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8655 - val_loss: 8.6988\n",
      "Epoch 16/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8647 - val_loss: 8.7013\n",
      "Epoch 17/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8639 - val_loss: 8.6988\n",
      "Epoch 18/50\n",
      "297020/297020 [==============================] - 17s 59us/step - loss: 0.8628 - val_loss: 8.6980\n",
      "Epoch 19/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8620 - val_loss: 8.6970\n",
      "Epoch 20/50\n",
      "297020/297020 [==============================] - 18s 60us/step - loss: 0.8609 - val_loss: 8.6995\n",
      "Epoch 21/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8603 - val_loss: 8.6997\n",
      "Epoch 22/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8597 - val_loss: 8.6963\n",
      "Epoch 23/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8593 - val_loss: 8.6989\n",
      "Epoch 24/50\n",
      "297020/297020 [==============================] - 17s 59us/step - loss: 0.8591 - val_loss: 8.7016\n",
      "Epoch 25/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8586 - val_loss: 8.6995\n",
      "Epoch 26/50\n",
      "297020/297020 [==============================] - 15s 52us/step - loss: 0.8576 - val_loss: 8.7040\n",
      "Epoch 27/50\n",
      "297020/297020 [==============================] - 16s 53us/step - loss: 0.8569 - val_loss: 8.7002\n",
      "Epoch 28/50\n",
      "297020/297020 [==============================] - 17s 58us/step - loss: 0.8561 - val_loss: 8.7044\n",
      "Epoch 29/50\n",
      "297020/297020 [==============================] - 16s 55us/step - loss: 0.8555 - val_loss: 8.6990\n",
      "Epoch 30/50\n",
      "297020/297020 [==============================] - 18s 59us/step - loss: 0.8550 - val_loss: 8.7012\n",
      "Epoch 31/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8546 - val_loss: 8.6979\n",
      "Epoch 32/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8541 - val_loss: 8.7022\n",
      "Epoch 33/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8541 - val_loss: 8.7029\n",
      "Epoch 34/50\n",
      "297020/297020 [==============================] - 17s 57us/step - loss: 0.8539 - val_loss: 8.7036\n",
      "Epoch 35/50\n",
      "116992/297020 [==========>...................] - ETA: 9s - loss: 0.8555"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-9fdf0cc623f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 validation_data=(test_dummy_std, test_dummy_std))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    183\u001b[0m                         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[1;32m--> 185\u001b[1;33m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[0;32m    186\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.fit(train_dummy_std, train_dummy_std,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(test_dummy_std, test_dummy_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = VanillaAutoencoder(n_feat=train_dummy_std.shape[1],\n",
    "                                 n_epoch=100,\n",
    "                                 batch_size=250,\n",
    "                                 encoder_layers=3,\n",
    "                                 decoder_layers=3,\n",
    "                                 n_hidden_units=100,\n",
    "                                 encoding_dim=50,\n",
    "                                 denoising=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 207914 samples, validate on 89106 samples\n",
      "Epoch 1/100\n",
      "207914/207914 [==============================] - 27s 132us/step - loss: 0.8960 - val_loss: 1.0644\n",
      "Epoch 2/100\n",
      "207914/207914 [==============================] - 26s 124us/step - loss: 0.8359 - val_loss: 1.0528\n",
      "Epoch 3/100\n",
      "207914/207914 [==============================] - 27s 129us/step - loss: 0.8285 - val_loss: 1.0597\n",
      "Epoch 4/100\n",
      "207914/207914 [==============================] - 26s 124us/step - loss: 0.8247 - val_loss: 1.0879\n",
      "Epoch 5/100\n",
      "207914/207914 [==============================] - 25s 118us/step - loss: 0.8224 - val_loss: 1.0771\n",
      "Epoch 6/100\n",
      "207914/207914 [==============================] - 23s 110us/step - loss: 0.8208 - val_loss: 1.0751\n",
      "Epoch 7/100\n",
      "207914/207914 [==============================] - 22s 108us/step - loss: 0.8194 - val_loss: 1.0307\n",
      "Epoch 8/100\n",
      "207914/207914 [==============================] - 24s 115us/step - loss: 0.8184 - val_loss: 1.0302\n",
      "Epoch 9/100\n",
      "207914/207914 [==============================] - 25s 121us/step - loss: 0.8172 - val_loss: 1.0211\n",
      "Epoch 10/100\n",
      "207914/207914 [==============================] - 24s 117us/step - loss: 0.8163 - val_loss: 1.0224\n",
      "Epoch 11/100\n",
      "207914/207914 [==============================] - 26s 125us/step - loss: 0.8149 - val_loss: 1.0234\n",
      "Epoch 12/100\n",
      "207914/207914 [==============================] - 26s 124us/step - loss: 0.8135 - val_loss: 1.0226\n",
      "Epoch 13/100\n",
      "207914/207914 [==============================] - 25s 120us/step - loss: 0.8116 - val_loss: 1.0165\n",
      "Epoch 14/100\n",
      "207914/207914 [==============================] - 25s 122us/step - loss: 0.8100 - val_loss: 1.0489\n",
      "Epoch 15/100\n",
      "207914/207914 [==============================] - 25s 121us/step - loss: 0.8083 - val_loss: 1.0608\n",
      "Epoch 16/100\n",
      "207914/207914 [==============================] - 25s 119us/step - loss: 0.8065 - val_loss: 1.0498\n",
      "Epoch 17/100\n",
      "207914/207914 [==============================] - 25s 118us/step - loss: 0.8048 - val_loss: 1.0260\n",
      "Epoch 18/100\n",
      "207914/207914 [==============================] - 28s 135us/step - loss: 0.8031 - val_loss: 1.0267\n",
      "Epoch 19/100\n",
      "207914/207914 [==============================] - 27s 129us/step - loss: 0.8017 - val_loss: 1.0274\n",
      "Epoch 20/100\n",
      "207914/207914 [==============================] - 27s 128us/step - loss: 0.7999 - val_loss: 1.0149\n",
      "Epoch 21/100\n",
      "207914/207914 [==============================] - 26s 125us/step - loss: 0.7984 - val_loss: 1.0128\n",
      "Epoch 22/100\n",
      "207914/207914 [==============================] - 22s 105us/step - loss: 0.7974 - val_loss: 1.0289\n",
      "Epoch 23/100\n",
      "207914/207914 [==============================] - 26s 123us/step - loss: 0.7963 - val_loss: 1.0122\n",
      "Epoch 24/100\n",
      "207914/207914 [==============================] - 27s 129us/step - loss: 0.7955 - val_loss: 1.0288\n",
      "Epoch 25/100\n",
      "207914/207914 [==============================] - 25s 119us/step - loss: 0.7947 - val_loss: 1.0424\n",
      "Epoch 26/100\n",
      "207914/207914 [==============================] - 24s 117us/step - loss: 0.7940 - val_loss: 1.0161\n",
      "Epoch 27/100\n",
      "207914/207914 [==============================] - 26s 123us/step - loss: 0.7933 - val_loss: 1.0140\n",
      "Epoch 28/100\n",
      "207914/207914 [==============================] - 28s 136us/step - loss: 0.7929 - val_loss: 1.0200\n",
      "Epoch 29/100\n",
      "207914/207914 [==============================] - 26s 127us/step - loss: 0.7924 - val_loss: 1.0377\n",
      "Epoch 30/100\n",
      "207914/207914 [==============================] - 28s 134us/step - loss: 0.7919 - val_loss: 1.0162\n",
      "Epoch 31/100\n",
      "207914/207914 [==============================] - 24s 115us/step - loss: 0.7917 - val_loss: 1.0104\n",
      "Epoch 32/100\n",
      "207914/207914 [==============================] - 25s 118us/step - loss: 0.7913 - val_loss: 1.0170\n",
      "Epoch 33/100\n",
      "207914/207914 [==============================] - 28s 135us/step - loss: 0.7910 - val_loss: 1.0096\n",
      "Epoch 34/100\n",
      "207914/207914 [==============================] - 24s 117us/step - loss: 0.7907 - val_loss: 1.0154\n",
      "Epoch 35/100\n",
      "207914/207914 [==============================] - 27s 128us/step - loss: 0.7904 - val_loss: 1.0118\n",
      "Epoch 36/100\n",
      "207914/207914 [==============================] - 28s 134us/step - loss: 0.7905 - val_loss: 1.0054\n",
      "Epoch 37/100\n",
      "207914/207914 [==============================] - 25s 119us/step - loss: 0.7901 - val_loss: 1.0350\n",
      "Epoch 38/100\n",
      "207914/207914 [==============================] - 25s 118us/step - loss: 0.7899 - val_loss: 1.0276\n",
      "Epoch 39/100\n",
      "207914/207914 [==============================] - 27s 128us/step - loss: 0.7896 - val_loss: 1.0133\n",
      "Epoch 40/100\n",
      "207914/207914 [==============================] - 27s 129us/step - loss: 0.7894 - val_loss: 1.0117\n",
      "Epoch 41/100\n",
      "207914/207914 [==============================] - 23s 111us/step - loss: 0.7893 - val_loss: 1.0313\n",
      "Epoch 42/100\n",
      "207914/207914 [==============================] - 23s 111us/step - loss: 0.7891 - val_loss: 1.0204\n",
      "Epoch 43/100\n",
      "207914/207914 [==============================] - 22s 104us/step - loss: 0.7891 - val_loss: 1.0264\n",
      "Epoch 44/100\n",
      "207914/207914 [==============================] - 22s 107us/step - loss: 0.7888 - val_loss: 1.0291\n",
      "Epoch 45/100\n",
      "207914/207914 [==============================] - 22s 106us/step - loss: 0.7887 - val_loss: 1.0265\n",
      "Epoch 46/100\n",
      "207914/207914 [==============================] - 22s 105us/step - loss: 0.7886 - val_loss: 1.0343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VanillaAutoencoder(batch_size=250, decoder_layers=3, denoising=None,\n",
       "          encoder_layers=3, encoding_dim=50, n_epoch=100, n_feat=382,\n",
       "          n_hidden_units=100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(train_dummy_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ae_feature = autoencoder.transform(train_dummy_std)\n",
    "train_ae_feature = pd.DataFrame(train_ae_feature, columns=[\"ae_feat_\" + str(i+1) for i in range(50)])\n",
    "test_ae_feature = autoencoder.transform(test_dummy_std)\n",
    "test_ae_feature = pd.DataFrame(test_ae_feature, columns=[\"ae_feat_\" + str(i+1) for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ae_feature[\"order_id\"] = train_set[\"order_id\"]\n",
    "train_ae_feature = train_ae_feature[[\"order_id\"] + list(train_ae_feature.columns[:-1])]\n",
    "test_ae_feature[\"order_id\"] = test_set[\"order_id\"]\n",
    "test_ae_feature = test_ae_feature[[\"order_id\"] + list(test_ae_feature.columns[:-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ae_feature.to_csv(\"train_ae_feature.csv\", encoding=\"utf-8\", index=False)\n",
    "test_ae_feature.to_csv(\"test_ae_feature.csv\", encoding=\"utf-8\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
